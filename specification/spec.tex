\documentclass[10pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage[colorlinks]{hyperref}
\usepackage[margin=2.5cm]{geometry}
\usepackage{parskip}
\usepackage{listings}
\usepackage[style=long,toc,xindy]{glossaries}
\makeglossaries
\setlength{\parindent}{15pt}
\author{Nicholas Clarke}
\title{Mercury specification}
\newcounter{paracounter}
\newcommand{\npar}{\par\noindent\refstepcounter{paracounter}\theparacounter.\space}
\include{glossary}
\begin{document}
\maketitle
\begin{abstract}
We present a specification for Mercury, a hypothetical pipeline system designed for use in human genetics workflows. Drawn from previous experience managing and running genetics pipelines, we identify a number of specific capabilities that would be desirable for the purpose of provenance tracking, repeatability and optimality of experiment workflows.
\end{abstract}
\tableofcontents
\section{Introduction}
\npar Within human genetics, there is a need to be able to design and execute specific \glspl{workflow} (\glspl{pipeline}) for genome analysis on a reliable, repeatable and efficient basis. At present, HGI runs a variety of pipelines for human genetics projects. These are run against a Linux cluster using Lustre-backed storage by the following two tools: 
\begin{itemize}
\item \href{https://github.com/VertebrateResequencing/vr-pipe}{VRPipe} runs as the \textit{orchestration} framework for current pipelines. It takes a description of the workflow (as a Perl script) and is responsible for tracking dependencies between jobs, submitting them to the executor and monitoring their progress.
\item \href{http://www-03.ibm.com/systems/technicalcomputing/platformcomputing/products/lsf/}{LSF} runs as the executor, responsible for taking an individual job and executing it on some compute resource. LSF additionally has the ability to manage job dependencies, but these features are not currently in use at the Sanger.
\end{itemize}
\npar Whilst these tools work suitably well for the general usage pattern at the Sanger, they show a number of limitations which it would be desirable to work around. In particular, HGI is interested in the areas of \textbf{data provenance}, \textbf{experiment repeatability}, \textbf{experiment isolation}, \textbf{pipeline optimisation} and \textbf{pipeline security}, hereafter referred to as PRIOS.
\npar Human Genetics has recently taken delivery of a new cluster (hgs4) intended primarily for pipeline usage. This presents us with the opportunity to re-evaluate our current toolset and practices and think about what we would really like in a pipeline execution system. This document presents a write-up of a series of meetings held on the topic, and is intended to serve as a specification for a potential future system embodying these desires.
\npar This document should ideally present the requirements for such a future system, and serve equally well as a guideline for the design of a new system or as a standard to evaluate existing systems by. Inevitably, however, we shall fall into the trap of starting to design a new system rather than just specify it. Where possible, sections that veer into design or even implementation will be flagged as such; it is quite likely, however, that some will escape. The reader is asked to bear this in mind when applying this document.
\section{The basics of a pipeline system}
\npar In this section, we briefly introduce the basics of a pipeline system as we would like it to operate. This should set the scene for the more specific goals and functional components outlined in following sections.
\npar We wish to build a system capable of taking an abstract description of a computation to run and running it against a specific dataset using particular resources. The description (hereafter referred to as a \gls{pipeline}) will in general consist of the composition of a set of individual steps. Each step itself takes a number of inputs and produces a number of outputs. The pipeline composes these steps by binding the output of one step to the input of another, forming a \textit{directed acyclic graph}. Each pipeline may have some unbound inputs and outputs - these represent the inputs and outputs of the pipeline itself. To run the pipeline, these inputs will be bound to specific data (we will say that we run the pipeline on that data) and the steps will be processed in dependency order to produce the output.
\subsection{Steps}
\npar In order to accurately describe a `step', we will build up from the simple case to the more general description which we will actually work with. With this in mind, then, we start by saying a \gls{primitive step} corresponds to a program that can be executed on a single host. Like all steps, a primitive step has inputs and outputs, which are themselves typed to specify what kind of data the step takes in and gives out. The pipeline executor will ultimately run each primitive step by assigning it to a particular host and set of resources (e.g. a certain amount of memory, a number of CPU cores) and binding its inputs to some pre-existing data. We call such a running step a \gls{job}.
\npar In many cases, a \gls{primitive step} will correspond to a way of invoking an existing program. It will have inputs corresponding to that program's inputs and configuration options. In order to convert existing programs to allow them to be run within a pipeline, one would write a wrapper to provide the missing semantics of a pipeline step to the standalone executable. For example, a wrapper would be responsible for declaring the types of data on which an executable operates, for specifying its inputs and outputs, and for correctly binding such inputs into a correct invocation of the program.
\npar A primitive step attempts to formalise an `action' or function which can be applied to some data. It does not correspond directly to a program - if a program has multiple modes of operation, then these should be represented by multiple primitive steps. Likewise, multiple versions of a command should correspond to different primitive steps. A primitive step may of course have inputs which correspond to configuration, and in some cases there may be an ambiguity as to whether to represent a parameter through an input or through different commands. Ultimately, this is at the discretion of the creator of the step, but we offer the following guidance: if the parameter changes the valid inputs and outputs, or if it massively changes the semantics of what is being done, it should be a new step. Otherwise, it should be an input.
\npar Technically, each pipeline could be constructed only of primitive steps. However, this would be quite laborious and each pipeline would end up quite specific to its particular use case. Rather than doing this, we describe two extensions to our concept of a step that allow the creation of significantly more flexible and reusable pipelines.
\npar Since each pipeline is itself a model of a computation with inputs and outputs, we may take a pipeline and include it inside another pipeline as a single step. When we treat a pipeline in such a way, we call it a \gls{composite step}. A composite step may of course contain other composite steps, and in such a way we hope to build up reusable components which may then be included in larger pipelines.
\npar Frequently, the modus operandi for pipeline jobs is to split the data into a number of pieces and operate independently on each piece. We could explicitly declare this by having an individual step for each piece of the data we wish to operate on. However, this would yield very complex pipelines which are specifically tuned to the number of pieces of data and contain a large amount of repetition. Instead, we introduce the concept of a parallel step. Some steps may take an input of an array type - e.g., the command `cat', which takes any number of files and concatenates them, might be of type $[File] \rightarrow File$ (if we redirect its output to disk). A parallel step takes as input an array of data but then operates on each element individually and in parallel. We can think of a parallel step as being the `map' combinator, with signature $(a \rightarrow b) \rightarrow [a] \rightarrow [b]$ which takes as parameters both the array of data and \textit{another step} which gets applied to each element.\footnote{One may, of course, generalise this and begin considering the idea of other higher order steps. There is potentially benefit in allowing the `bind' or `fold' combinators, which allow us to implement a great deal more. However, we shall not explore this area for now, and it may be expedient to hide this formalism even if we use it.}
\npar Parallel and composite steps are separate and non-interacting abstractions - one may have a composite step included in a parallel step, or a parallel step inside a composite step.
\npar Whilst we have gained generality with these new types of steps, we have lost one of the fundamental features of \glspl{primitive step} - that each one could be executed on a host. In the next section we detail how we propose to regain this feature from our now higher-level model.
\subsection{Pipelines}
\npar By expanding our definition of what a step can be, we have complicated our notion of how a pipeline is to be executed. In this section we propose some distinctions which underlie our use of the term `pipeline' and which provide us with a means to recover the execution semantics of a pipeline composed only of primitive steps. Unlike in the previous section, where we started at the simple level and built abstractions, we shall start with the highest abstraction and detail the deconstruction into primitives.
\subsubsection{Abstract Pipeline}
\npar At the highest level, we have the \gls{abstract pipeline}. An abstract pipeline corresponds most exactly to a top-level description of a series of actions we would like to have performed against some data. A typical description might be ``A pipeline for BAM improvement using Samtools'', or similar; abstract pipelines might be suitable to expose to customers in some sort of catalogue, offering the various services we can run.
\npar An abstract pipeline may be composed of primitive, composite and parallel steps. It also has a number of free\footnote{\href{http://en.wikipedia.org/wiki/Free_variables_and_bound_variables}{Wikipedia: Free and bound variables}} inputs and outputs. This makes an abstract pipeline reusable between multiple inputs, and also allows it to be included as a composite step in other pipelines.
\npar An abstract pipeline must in general have \textit{some} free inputs and outputs (or else it has no effect), but this is not to say that all inputs to steps which are not connected to the output of another step must be free. For example, inputs corresponding to configuration parameters may be bound to static values in an abstract pipeline.
\subsubsection{Configured Pipeline}
\npar At some point, one needs to decide what data is going to be run through the pipeline, and bind the free variables of an abstract pipeline to values identifying where to get the input from. We shall call an abstract pipeline with all inputs and outputs bound a \gls{configured pipeline}. A configured pipeline represents a standard request made to HGI to run one of our pipelines on a particular project's data.
\npar A configured pipeline still retains the high-level description of steps to execute, being composed of composite, parallel and primitive steps.
\subsubsection{Executable Pipeline}
\npar At some point, each of the composite and parallel steps need to be compiled into the concrete set of primitive steps which will be executed on compute hosts. This process takes a configured plan and expands the composite and parallel steps into multiple primitive steps to produce what we shall call an \gls{executable pipeline}.
\npar The exact process of producing an executable pipeline is discussed in more detail in subsequent sections, in particular on optimisation (see \ref{sec:optimisation}).
\section{Goals}
\npar In the introduction, we introduced some high-level goals in which HGI has a particular interest. These are not requirements in their own right, being too high-level, but should give rise to requirements in the same way as other top-level goals such as 'the system must be usable'. In this section, we'll take a look at these goals, elaborating on and discussing them in order to provide context and motivation for the requirements introduced in the following sections.
\subsection{PRIOS Goals}
\subsubsection{Data Provenance}
\label{sec:provenance}
\npar Data provenance is fundamentally about being able to ask the question ``Where did this data come from?'' For a given set of data, we want to be able to identify which pipeline(s) it was created from, what steps were involved, where the initial data came from, how the jobs were distributed amongst machines and what was running on the machines at the time? As far as possible, we would like to be able to identify precisely what happened to cause the data to be generated as they were.
\npar There are various justifications for this. Partially, it is about repeatability (as in the next section) - being able to identify how something came about makes it much easier to repeat it. Partially it is about data integrity - being certain that results were generated using the precise input data which you thought they were. Optimisation also calls for provenance data - once we understand how precisely data were generated, we know how expensive they are to recreate and how important it is to store them. And, in part, we want to be able to document the process for users' own purposes, so they can check what happened as part of an analysis run by HGI.
\npar Implementing provenance tracking leads to a number of requirements. We need to keep track of pipelines both as designed (in general, without specific reference to data) and as executed (on which hosts, at what time). We need to ensure that external dependencies are explicitly captured (which in turn leads to the isolation goal), and isolated both in the planning stage (separating external I/O from internal - e.g. passing data between steps in a pipeline) and in the execution stage, preventing steps from unknowingly accessing external resources.
\npar Provenance tracking becomes slightly more tricky with the inclusion of optimisations that enable reuse of results (see section \ref{sec:optimisation}). This is because the same data may be generated in multiple ways by multiple people, or, in some cases, may be used in one experiment having been generated in an entirely different way by another (but where we have evidence that the results will be identical - perhaps through carrying out a third experiment). At a tracking level, this problem is not difficult - we should, as a matter of course, track \textit{every} time data is generated or recovered from a cache, with an indication of which pipeline and pipeline components generated it and whether it was actually generated or cache-recovered. When presenting these data to users, however, thought must be given to how to deduce the \textit{correct} provenance for any particular enquiry from the context of the question.
\subsubsection{Experiment Repeatability}
\label{sec:repeatability}
\npar Following on from provenance, we have the goal of making our pipelines repeatable. This goes a step further than provenance; rather than simply identifying where data comes from, we would like to be able to recreate it, in spite of potential changes to the underlying infrastructure. 
\npar This gives rise to the ideas of encapsulation already implemented in Mercury capsules, wrapping up an environment suitable to run a step of the pipeline. Whilst capsules provide repeatability of individual steps, we are also forced to consider repeatability of the entire pipeline, which requires us to suitably abstract away from specific hardware or infrastructure constraints. This is one advantage to moving away from the current LSF-based approach, for example.
\npar Also covered under repeatability is the requirement to rerun an experiment whilst changing a fixed number of factors, and tracking effects. For example, we might want to rerun an old pipeline using a new version of a particular piece of software to see whether it meaningfully alters the output. This same idea applies to rerunning a pipeline on new data.
\subsubsection{Experiment Isolation}
\npar Isolation is, in many ways, an enabling goal. Isolation of experiment processing allows us to be certain of the provenance of generated results, and enables us to move the isolated experiment to another system to repeat it. By isolating each pipeline (and each step of the pipeline), we enable meaningful statistics to be gathered about resource usage and running profile to allow for optimisation, and prevent other systems from interfering with the processing in order to provide security.
\npar Isolation principally sets requirements on the execution of individual jobs, where we need to isolate the actual processing from other jobs on the same host, as well as from the wider environment. Isolation plays into the design of Mercury capsules, which wrap processing up in LXC-based virtual machines. We must also bear it in mind when considering the orchestration component, though it would be strange if pipelines were not conceptually isolated at this level. Care must be given to the interactions of isolation with optimisation of pipelines which share components. We wish to ensure that shared work is not duplicated, but carefully isolate the parts of processing unique to each pipeline.
\subsubsection{Pipeline Optimisation}
\label{sec:optimisation}
\npar It has been observed in many places that as the costs for sequencing drop at a faster rate than the costs for processing and storage, we will need to be significantly more efficient in how we process and store sequencing data. Even without this driver, however, we would like to take full advantage of the resources available to us for computation. We need to balance this with the semi-competing desires to be \textit{fair}, which is probably to say that there should be no strategy allowing any subgroup of users to guarantee control of an arbitrarily high proportion of the compute resources, and to support variable allocation of resources to different uses.
\npar Currently, there are a number of tools in place to try to aid in this process. VRPipe does some resource tracking to try to avoid duplicating previously run jobs, and makes some attempt to estimate the resource requirements of a job in order to avoid requesting more resources than are necessary. LSF then uses a `fairshare' system to allocate resources to users in a way which tries to maximise allocation whilst ensuring that everyone gets appropriate usage rights. Whilst these are good ideas, their implementation has much room for improvement. VRPipe does not handle inter-pipeline sharing and its resource estimation is rudimentary. Likewise, whilst the fairshare features in LSF are probably fair (whilst there are dominant strategies, they generally involve exploiting other parts of the system and so might be considered `cheating'), they do not encourage efficient resource usage: a common situation is for there to be a surfeit of CPUs available for low-memory jobs, but a disincentive to use them because this harms the global priority you might need to compete for more contested resources. People don't want to eat the boring biscuits in case they are placed lower in the queue for when the chocolate coated ones come around, and so we have a load of boring biscuits being passed around uneaten.
\npar We would like Mercury to take these ideas (and a few others) and develop them. This can be broken down into a few sub-themes:
\begin{enumerate}
\item Firstly, we would like to empirically determine the relative costs of storage and compute. By capturing rich data on how expensive a job is and how large are the data it generates, we can build a picture of a `reasonable' exchange rate between compute time (and other resources) and storage costs. For example, if we know that on average it costs 4 CPU-hours and 2 GB-hours of memory to produce 100GB of output data, then we might infer that something costing 10 CPU-hours and 5 GB-hours of memory but producing only 1GB of output is a very efficient usage of storage over compute. In terms of time/memory trade-offs, this is an ideal candidate for caching. Conversely, something costing a single CPU-hour and 512Mb hours of RAM but producing 50Gb of output is extremely cheap to produce compared to how much it costs to store, and we should almost never keep it around.
\item Separately, but relatedly, we would like to support demand-based pricing of the various resources available to the system (CPU, Memory, I/O etc) and a `fairshare' like system built around this pricing model. At the user-facing level, this would hopefully address some of the problems with the current system in terms of `cheap' resources being underutilised - where there is low demand on a particular resource, the price would drop until demand rose.

At the system level, this model would give us the additional information needed to engage in deliberate currency trading between storage and compute, providing another method to increase efficiency. For example, if we found ourselves with CPU resources in very high demand but a surfeit of disk space, we might choose to `buy' CPU resource by aggressively caching data, lowering the cost of compute at the expense of cost for disk space.\footnote{One can imagine a scenario where we might attempt to do similarly for resources such as CPU and memory by literally trading with other clusters - perhaps offering cheap pricing for CPU-intensive low-memory jobs in return for cheap access to lots of memory. One can imagine this, but we shall discuss it no further in this paper.}
\item Once we are in possession of the mechanisms for evaluating the costs of TMTOs and similar techniques, we would like an infrastructure capable of taking advantage of this as much as possible. To do this it is necessary to identify where multiple pipelines share components and aggressively de-duplicate processing. This should occur both with concurrent pipelines (where shared steps are 'merged') and with pipelines which repeat work previously done by another pipeline. As mentioned in section \ref{sec:provenance} on provenance, this must be done both on pipelines `as designed', where we de-duplicate steps which are conceptually the same, and `as executed', where we de-duplicate steps which are executed in the same way.

As an example of this last point, we consider three related pipelines which calculate summary statistics on a list of numbers. They can be described as follows:
\begin{enumerate}
\item Pipeline a runs on a file containing the numbers 0 to 99. It splits this file into parts $ \{F_n\}_{n \leq N} $ where $ F_n := [N*n, N*(n+1) \wedge 100) $. It then operates in parallel on each $F_n$, counting how many odd numbers are contained in $ F_n $. At the end, the results from each $ F_n $ are summed to give us the count of odd numbers in the original file.
\item Pipeline b is almost identical to pipeline a, except that a different number $ M \neq N $ is picked for the size of splits (We have not yet mentioned the mechanism by which this parameter might be `picked' - more on this in the next subsection).
\item Pipeline c behaves much as pipeline a, except that it operates on a file containing the numbers 0 to 49. The number $ N $ is chosen identically with pipeline a.
\end{enumerate}

In this case, pipelines a and b are both doing the same thing as designed. Abstracting over the detail for now, we would like to think of wrapping up the entire process of splitting, operating in parallel and summing into a single step, `count odd numbers', whose result should be fully determined by its input. Under this abstraction, pipelines a and b are identical, and so it should be valid to re-use the end results from a for pipeline b.

Pipelines a and c, on the other hand, are operating on different files, and the input to the `count odd numbers' step is different. However, when we split the file in c into its five parts, we see that those five parts have already been processed as part of pipeline a, and as such we can reuse those parts. Whilst the pipelines are different in design, they share steps as executed, and these steps can also be de-duplicated.
\item In the previous point, we alluded to the idea of `picking' $N$, the chunk size to split the file into before processing chunks in parallel. Parameters such as $N$ may exist in many pipelines - parameters which do not (or should not) affect the outcome of the pipeline but which may have a massive effect on the runtime behaviour and performance characteristics. Taking $N$ as an example, for very high values of $N$ we have very large lists of numbers being processed in serial on a single machine, which could be very slow if we were doing more than counting odd numbers. Conversely, if we pick $N$ to be very small (1, say), we split the file into a very large number of jobs, each of whose overheads are likely to dominate the actual cost of processing the file. Somewhere between these is an optimal value which balances the overheads of multiple processing with the parallelism offered.

Furthermore, since we do not just care about the fastest execution, but about the total \textit{cost} of the job, the best parameter values will depend not only on the job but on the demand and availability of resources. For example, if there are currently a large number of single-CPU low-memory slots available in our earlier example, it may be advantageous to set $N$ low in order to fit into the low-memory slots, whilst if there are large machines around we may wish to simply use a single machine to blow through the whole list.

For cases such as splitting files and operating in parallel, but potentially other parameters, we would like the system to be able to choose a value for the parameter to take advantage of its knowledge of current resource prices and empirical data on the execution parameters of that job. This shifting of responsibility from the user to the system should allow for a more efficient execution, but also removes some of the control from the user in terms of their specific goals. For example, they might not wish to minimise cost but just get the fastest execution regardless of price. To cover this situation, we suggest that the system might implement different strategies for choosing parameter values. The default strategy might be to minimise cost, but another could attempt to minimise runtime, or minimise runtime subject to a cap on cost.
\end{enumerate}
\npar In terms of requirements resulting from these goals, there are a number. As already mentioned in sections \ref{sec:provenance} and \ref{sec:repeatability}, we need to track data about the resources used in pipeline execution and storage. We need the flexibility to perform trade-offs between storage and compute, which means the system needs to `own' its own storage, able to perform deletions or compaction without this being noticed by users. We need to track provenance information in order to decide whether data should be reused from a previous run. We also need a way of indicating that a given step is \textit{not} recreatable - for example, because it talks to an external resource which we do not govern.
\npar The need to de-duplicate at multiple levels, and to allow certain parameters to be picked by the runtime, requires that we have some conception (or at least record) of pipelines at multiple levels of abstraction, and to track the results as seen from each of those levels.
\subsubsection{Security}
\npar After the \textit{tour de force} of optimisation, there is comparatively little to say about security, which is mostly interesting for how it interacts with some of the other goals (principally optimisation). We break down security into the classic three security attributes of confidentiality, integrity and availability:
\begin{itemize}
\item \textbf{Confidentiality} - The Mercury system will occasionally be required to process vaguely personally-attributable data which could be considered sensitive. It needs to ensure that data inside its system remains accessible only to those with the correct permissions, and that any data it imports on behalf of users is accessed with their permissions only. However, this should be done whilst trying to avoid multiple independent copies of sensitive data being worked on separately within the system. Where multiple people are working on the same sensitive data, the system needs to be intelligent enough to realise this and update the permissions accordingly.
\item \textbf{Integrity} - Data integrity covers the ability of the system to ensure the correctness of generated data even in the presence of errors, along with the ability to provide sufficient evidence for that correctness. The latter, for a previously generated dataset, is covered mostly by the trail of provenance data which we collect, dealt with already in section \ref{sec:provenance}. Ensuring the correctness of data in the presence of errors will require both a resilient system capable of detecting and sensibly handling errors (dealt with in the later section on \ref{sec:resilience}), and a system of checks and balances which guard against errors outside of the control of the system - for example, capable of detecting corruption in data as it moves between steps.
\item \textbf{Availability} - This comes in two flavours - availability of generated results, and availability of the pipeline system. The latter we will cover later in the more appropriate later section \ref{sec:resilience} on resilience. The former involves the semantics for data which leaves the system's direct control. In general, we may not wish to maintain separate copies of the data inside Mercury's control and outside of it. However, data that has left the system is no longer under the total control of Mercury - it cannot decide to delete it, for example. Some conception would be desirable for referencing data which has left the system in such a way that it can still be drawn back in for pipeline use.
\end{itemize}
\subsection{Other goals}
\npar The PRIOS goals represent a specific area in which HGI is particularly interested in extending our pipeline systems. However, there are also a number of other goals which are intrinsic to the proposed system being useful and suitable as a general replacement for the current Mercury pipeline system. We address these in the following section.
\subsubsection{Resilience}
\label{sec:resilience}
\npar Running over a large-scale cluster, errors with individual low probability become a regular occurrence, and we therefore require our system to deal with them accordingly. Further, leaving aside even the error case, the Mercury system will rely on a number of tools outside its control. In the initial conception, Mercury at the Sanger will be running on a number of private compute nodes as well as some shared with other uses, using two or three distinct Lustre storage units for scratch storage. Any of these units may be taken down for reasons outside of Mercury's (or HGI's) control, and Mercury must be able to cope with these outages.
\npar Resilience starts with the ability to self-monitor; Mercury needs to be able to detect failures and handle them gracefully. These failures may occur in many different places: in an individual job, on a host, at the network level, in the job planner, with a specific resource (e.g. a particular Lustre unit), with external I/O, and so on. Each of these error modes may need to be handled differently. The system needs to be able to identify various classes of error, handle immediate consequences, perhaps investigate further, maintain an internal awareness of what is working and what is not, and report back to users, HGI or Systems.
\npar The first responsibility upon detecting an error is to ensure the integrity of associated data. Where errors have been detected on a node, or with a particular resource, this may taint recent results which have been generated on that node or using that resource. The pipeline may need to decide to backtrack and rerun certain steps whose results are now suspect. A failing node will need to be closed to new jobs until the system (or a user) can verify it is working correctly. Where there are more transient errors, such as reading a file from disk and getting an invalid checksum, it may only be necessary to restart the step in question, though if such an error persists then the pipeline may need to backtrack.
\npar After guaranteeing the integrity of working data following an error, the system should also attempt to continue running to the best of its ability with whatever capability it has remaining. If a pipeline depends on data which is no longer available, it could attempt to recreate that data in another location (subject to resource constraints and the likelihood of the original data becoming available again). Jobs should be restarted on working hosts. Of course, failures in the system may well result in large price increases as a lower number of resources are available to service an increased demand!
\npar There are certain places where simply monitoring for failure and acting accordingly will not work. For example, should the core metadata system fail, then there is very little the system can do (except, perhaps, keep running existing jobs in the hope that it will come back up). Where we have examples such as this, we must instead consider resilience to an initial error - for example, by supporting multiple fail-over metadata servers with some communication between them.
\subsubsection{Flexibility}
\label{sec:flexibility}
\npar The current pipelines used by HGI are somewhat specific to Sanger infrastructure, tied to LSF and Lustre and our current use of them. Whilst this is in no way a problem at present, we can envision wanting to replace these at some time in the future, or to hook other resources into the system and allow them to be used. We may also wish to run Mercury at places other than the Sanger which have quite different infrastructure.
\npar We would therefore like to be generally flexible as to the required infrastructure supporting Mercury. Without going into too much detail, here are some ideas of things which we do and do not expect to rely on.
\begin{itemize}
\item Things we expect to rely on:
\begin{enumerate}
\item Linux - this is an implicit requirement of many of the tools we use, and there's almost no call for running on anything else.
\end{enumerate}
\item Things we may come to rely on:
\begin{enumerate}
\item LXC - this is currently our expected method for containerisation of jobs, and we don't think this will change. However, it's possible that the \glspl{job executor} could be made sovereign of the container mechanism used to actually run its jobs, subject to a sufficiently rich interface between the two. However, it's not clear that it's worth the cost of doing this.
\item Mesos - or at least a similar meta-scheduler. This is not a necessary dependency, and the interface is very simple, which is why it seems fair to consider it. Mercury could operate directly against compute resources which it owns, but this would require it to implement much of Mesos's functionality whilst losing the benefit of running other schedulers under it.
\item A higher level containerisation tool, such as \href{https://www.docker.io/}{Docker} or \href{https://github.com/wtsi-hgi/hgc-tools}{hgc-deploy}. Whilst LXC provides the mechanism by which containers are run, it does not possess tools for managing them or to provide the various other capabilities desired, such as mounting specific resources into the container. For this, we may come to rely on a higher-level tool.
\end{enumerate}
\item Things we would like not to rely on:
\begin{enumerate}
\item Storage mechanisms - current pipelines are reliant on traditional Posix-based file systems for their working storage. However, there are often better choices to be made for certain types of access pattern. For example, one way of abusing Lustre is to write millions of small files, which causes congestion on the metadata server. A key-value style store, however, is perfect for storing many small documents, so may well be a better choice for this access pattern. Where small amounts of data are being passed around between jobs, we may not want to go to the expense of writing to disk at all, and use something like a memcached server to persist data between jobs.

Mercury will ideally be able to support multiple different backing storage mechanisms, and be able to choose between them according to the particular situation.
\item Host software - by taking advantage of containerisation we aim to reduce the requirements on the individual host to being able to run a job executor and a container. This should eliminate problems with the software configuration on a host.
\end{enumerate}
\end{itemize}
\npar In section \ref{sec:repeatability} we talk about the goal of wishing to enable repeatability of an experiment in another place, or at some time in the future. Whilst the minimal requirements we describe here should allow pipelines to continue running for some time, there will inevitably come a time when changes to the kernel version or LXC result in the breaking of existing pipelines. In order to overcome this problem, we may have to move towards full virtualisation of older Linux versions, rather than simply using container level virtualisation.
\npar There are two potential approaches to this. The first would deploy VMs running the requisite O/S versions independently of Mercury, and then run Mercury agents inside the VM to connect these VMs to the wider cluster for use in older pipelines. This has the advantage of requiring no special support from Mercury, but has the disadvantages of needing another infrastructure to manage, and making it very difficult to run multiple different pipelines requiring different base versions of the O/S. The second approach would be to introduce a second container system which uses a VM to run an LXC container within it. This would need to expose the same type of container interface as the LXC-based containers, but could delegate much of the work to the internal LXC instance.
\subsubsection{Scalability}
\npar As our demands for computation increase, it may be increasingly implausible to carry out all computation in house using pre-assigned resources. Whilst we assume that the hgs4 cluster may run Mercury constantly, we may also wish to use other resources such as the general clusters to expand Mercury on a temporary basis, either to cope with periods of increased demand, or to deal with particular jobs possessing unusual requirements.
\npar Mercury needs to be built to cope with the idea of its fundamental resources - whether in the form of compute nodes or storage resources - being transitory, subject to expansion or removal even during pipeline execution. It should be easy to add a new resource for use by Mercury and have existing Pipelines seamlessly modified to take advantage of it. Likewise when a resource is removed from the system.
\npar Using \href{http://mesos.apache.org/}{Mesos} as in our preferred deployment option would provide the above capability for compute nodes. However, we still need to consider how to do the same for storage resources (or any other resources not considered here), and if we do not use Mesos (or a similar solution) then we must support this for compute resources as well.
\subsection{Miscellany}
\npar From our experience in dealing with existing requirements have come about a number of use cases which do not fit neatly into the high-level goals set out above, but which nonetheless represent concerns we should take into consideration when designing our system. We expect that these cases may be considered as extensions to the system rather than critical parts of the core system. However, the ability to admit such extensions must be seen as a goal for the system itself.
\subsubsection{Checkpointing and Migration}
\npar The information available to the scheduler when it comes to making decisions about which jobs to schedule is sadly imperfect. As far as possible, it should take advantage of the knowledge available to it - the size of the input, empirical data about how long a step usually takes to run, etc. - to make reasonable assumptions about the resource profile of a job, but inevitably these assumptions will be incorrect.
\npar The scheduler should be perfectly happy to make decisions based upon this incorrect knowledge. However, it should also be able to change its mind at a later point when further information becomes available. One possibility for this is to simply kill the job and reschedule it later, but this may be expensive if it has already carried out significant amounts of work. The alternative is to take advantage of a \gls{checkpoint} system which will try to save the state of a job for subsequent resumption later.
\npar Checkpointing may also be used for other reasons. For example, if we know a host is going down (see section \ref{sec:outagePlanner} below) then we might want to suspend all jobs running on it and migrate them to another host. We can also do this if we believe a job is trying to expand beyond the resources available to it.
\npar Whilst potentially cheaper than restarting a long-running job, checkpointing itself has a cost in terms of storage space required to serialise running memory. Where jobs are using large amounts of memory, checkpointing may be more expensive than restarting, and this cost should be considered as any other when considering whether to perform a checkpoint/restart.
\npar Checkpointing itself is a feature offered by external tools. Currently we use Berkeley Linux Checkpoint/Restart, although there are potentially newer implementations within the Linux kernel itself. Mercury should not express a dependency on any one of these tools, but needs to understand the concept of a suspended job, and the mechanisms for suspending and then restarting a job as part of normal resource management.
\subsubsection{Generalised Assertions}
\npar One of the fundamental ideas we wish to take advantage of is that for certain steps (\textit{pure} or \textit{referentially transparent} steps), we may replace an invocation of a step $ f $ on arguments $ (a_i) $ with the result of a prior invocation of that same $ f $ on those same arguments. Even where we do not have those results cached, we may use this identity to reason about subsequent behaviour of the pipeline - for example, we may decide that we don't need to run it at all if we believe it will generate precisely the same results as a previously executed pipeline.
\npar This observation lies at the heart of much of the optimisation strategy detailed above in section \ref{sec:optimisation}. However, it is in many ways a blunt instrument, with only two possibilities. Sometimes we would like to be more general. For example, we might wish to state that a particular output of a step depends on one of its inputs, but not the other. Alternatively, we might get a new version of a piece of software which we wish to use for performance reasons, but where we believe that the results should not differ from the previous version. In this case, we might assert that any results generated by the previous version can be used for pipelines running the new version, and vice versa.
\npar We call such things generalised assertions. Generalised assertions are principally of use to the pipeline planning system - they determine where it should look to determine whether or not a step of a pipeline needs to run.
\subsubsection{Quickcheck-style self testing}
\npar In the previous section, we discussed the purity and how we could use this for pipeline optimisations. However, because we have actually worked with some of the software these pipelines will be running, we are a little sceptical of claims made by particular programs to being pure. As such, we would like Mercury to follow a `trust and verify' scheme. In general, we will assume that they do what they say, and will always return the same output for the same input. Sometimes, however, particularly when resources are very cheap owing to low utilisation, the system may decide to rerun supposedly pure components in order to verify that they are doing what they claim to do.
\npar We may wish to do the same thing for any of the generalised assertions mentioned in the previous section. On occasion, we might want to go the other way - rather than trust and verify, we would distrust until we had enough confidence in the result, and only then assert such behaviour. This seems particularly likely in cases where a particular version of software is updated - we may not wish to trust anything without checking it first.
\npar Mercury should ideally allow for support of both styles of property testing in a nice way, using previously run experiments as the source of data to test the system with.
\subsubsection{Outage planner}
\label{sec:outagePlanner}
\npar In contrast to errors, we often know well in advance when outages for critical resources are going to occur. Given this, we should be able to take advantage of this foreknowledge in order to better make use of resources in and around the outage.
\npar For example, on receiving knowledge that a storage system is going down, we might identify resources which are going to be needed by queued pipelines and begin moving them to another resource in advance of the outage. Meanwhile, very short or cheap jobs could be moved to using the soon to be outed resource in the knowledge that they will either finish before the outage or be cheap enough to replicate if taken down by it.
\npar Ideally, one would be able to tell Mercury about the outage schedule of particular resources and have this information used when deciding how to assign resources to particular pipelines or jobs.
\subsubsection{Streaming}
\npar In order to execute a pipeline, Mercury will need to perform a partial linearisation of the dependency graph - in other words, forcing jobs that serve as dependencies for others to be performed first. This will not form a total order, since some jobs may be independent of each other and may run simultaneously. In general, within each ordered chain, jobs will be executed sequentially, with one job running, outputting, and exiting before the next is allowed to start. This is a sensible strategy to assume for programs which, say, write their output to a file which another program will attempt to perform random accesses into.
\npar However, Unix has long supported another method of sequencing steps in a computation using its streaming pipe operator. In this model, data is streamed directly from one job to the next without requiring writing to disk in the meantime. This works very well for jobs which simply read a file sequentially.
\npar One way for Mercury to support this would be to require each chain of streaming components to be packaged as a single step, and rely on the underlying host to handle the streaming. This is below optimal for many reasons. Firstly, it increases the size and complexity of the \glspl{primitive step}, which decreases compositionality and increases duplication. Secondly, it it excludes all of Mercury's checksums, caches and other optimisations taking place between components (see figure \ref{fig:streaming:bigPrimitives}). Finally, we limit streaming composition of jobs to a single host, which raises the bar for hosts we can use and again decreases Mercury's ability to optimise for best usage of its resources.
\begin{figure}
\lstset{language=Bash,
		xleftmargin=.2\textwidth,
		xrightmargin=.2\textwidth
		}
\begin{lstlisting}
seq 1 1000000 | filterPrimes
seq 1 1000000 | filterPrimes | head -n 5
\end{lstlisting}
\caption{If we run the two commands above as separate primitive steps, we cannot take advantage of any caching or optimisation between them, and so we must compute the expensive `filterPrime' each time, despite the fact that we could re-use it. }
\label{fig:streaming:bigPrimitives}
\end{figure}
\npar As such, we would like for Mercury to support this at a higher level, allowing jobs to be connected together with `streaming' arrows rather than conventional ones. Clearly, this would only be possible for certain jobs which advertise to work with streaming data, although since streaming can be seen as more general than a sequential approach, it should be possible to connect streaming jobs to conventional ones through simply streaming to/from disk, although with none of the benefits.
\npar Connecting two streamable blocks with a streaming arrow would effect the following changes in behaviour:
\begin{enumerate}
\item The second job could be scheduled to start as soon as the first job starts, rather than as soon as the first job finishes. In general, we would like the jobs to start as concurrently as possible, in order as to not have the first job blocking on I/O whilst waiting for the second.
\item Rather than output and input being connected to one of the standard resources, they would be connected to a `special' resource which would not store data but stream it between them. Note, however, that this resource may choose to do other things, such as checksumming the data or copying it to another resource for storage.
\end{enumerate}
\subsubsection{MPI}
\npar Mercury as we have described it is designed mainly for running, in parallel, a large number of jobs which have no inter-dependencies. Where dependencies do exist, linearisation is performed to ensure that one job must complete before the next can start. It might be nice to allow for the running of jobs which are inherently parallel, requiring deployment onto multiple hosts but managing the process of inter-host communication themselves. MPI is the canonical example of how such a job might work.
\npar There is a reasonably strong argument that Mercury would be the wrong framework to run such jobs in, however. Firstly, Mercury is intended (see section \ref{sec:flexibility}) to be flexible as to its underlying hardware and network model. Making direct network communications to other nodes available to running jobs would break that abstraction somewhat, and could be problematic when some parts of a job are deployed onto different network segments, or even sent off to Amazon or somewhere for processing.
\npar This objection could be worked around with judicious use of a resource constraints approach, where a job could be specified to require a certain network or similar. However, the second major objection to this behaviour is that it requires out-of-band communication between nodes, making it more difficult to ensure things such as data provenance and repeatability.
\npar This is not to say that we do not see a place for such jobs; indeed, we believe that their importance is only going to grow. However, it may be that they are better handled by higher level frameworks such as Hadoop which gain more powerful semantics for reasoning about parallel jobs through the sacrifice of flexibility as to how a job operates. Our preferred scenario for the deployment of Mercury has it running atop of \href{http://mesos.apache.org/}{Mesos}, a meta-scheduler allowing resources to be shared between multiple scheduling frameworks. This would allow Mercury to run alongside Hadoop, servicing different type of jobs.
\npar All of that having been said, it may be that there is still a desire to include MPI-type jobs into the purview of Mercury. This problem is unlikely to be insurmountable, but would require that we consider safe ways of constraining network communication, of passing \glspl{metadata} (e.g. host addresses) into jobs, and of generalised resource constraints which would allow, for example, a \gls{step} to specify that all jobs resulting from it must be deployed onto the same network segment.
\section{External Interactions}
\npar Covered under this heading are the various ways in which we wish Mercury to interact with other people and systems. This does not cover systems upon which Mercury itself relies (which can be seen as implementation details) but does cover the various ways in which other systems can expect to rely on Mercury.
\npar This section will be divided in the following way: firstly, we shall cover the expected interactions with users, divided into the various roles we see interacting with the system. Secondly, we shall deal with the expected interactions with external systems.
\subsection{User Interactions}
\subsubsection{Mercury Administrator}
\npar The Mercury administrator (typically a member of HGI) will be responsible for the overall operation and stability of the system. They will need to interact with the system in the following ways:
\begin{itemize}
\item Starting and stopping the system as a whole.
\item Adding and removing compute nodes from the system.
\item Adding and removing other resources (e.g. storage resources) from the system.
\item Managing systemwide configuration; for example, tuning GC thresholds for storage devices.
\item (Exceptionally) Manual intervention in normal system processing - for example, causing a previously run pipeline to be purged from the system, or requiring that a data object be removed.
\item Configuring user/group permissions and quotas (though see \ref{sec:interactions:ldap} below).
\item Management of jobs with the permissions of the job owner.
\end{itemize}
\subsubsection{Step Creator}
\npar Step creators are responsible for developing new \glspl{step}. These may represent new pieces of software, new capability build specifically for Mercury, or new versions of pieces of software for which steps already exist. Step developers will almost certainly operate within HGI.
\npar For the most part, step development will take place outside of Mercury, and will consist of writing the step description (in whatever language is deemed appropriate for that purpose) and specifying the appropriate container to run the step. However, the step creator will need to interact with the system to:
\begin{itemize}
\item Get a list of existing steps.
\item Register a new step with the system.
\end{itemize}
\npar The step developer may also need a means to test a step before `officially' registering it with the system. This may take the form of a tool which runs a step in isolation, so that it can be tested manually on the command line without connecting it to a wider pipeline.
\subsubsection{Pipeline Creator}
\npar Pipeline creators are responsible for developing new pipelines (specifically, \glspl{abstract pipeline}) from existing steps or creating new versions of existing pipelines. Initially, pipeline authors are likely to be working within or closely with HGI; however, we would ideally like to enable faculty groups to develop their own pipelines. Pipeline developers will need to:
\begin{itemize}
\item Obtain a list of pipelines already registered within the system.
\item Register a new pipeline within the system.
\item Test pipelines.
\end{itemize}
\npar The final point is perhaps the most difficult to achieve, and the most expedient to discuss. When creating a pipeline from scratch, or even from an existing pipeline, many iterations may be needed before the final solution is reached. These iterations are each, in themselves, a theoretically runnable pipeline, but they may result in errors at runtime or generate useless results.
\npar There are two questions for us to consider in this regard. Firstly, how to sensibly test a pipeline within a system which is designed to otherwise run pipelines without user interaction. Secondly, how to handle the results generated from these early versions of pipelines which are in testing.
\npar On the first issue, we want to ensure that a pipeline creator is able to do the following two things: running parts of the pipeline in isolation, and inspecting results and parameters at all stages through the pipeline. The former can partly be helped by the earlier mentioned tool to run a single step outside of the control of Mercury, which would allow individual components to be tested one-by-one. The second could be achieved through exposing (in some fashion) the intermediate results that remain under the control of Mercury. This could be through copying them out to another storage location, or writing them out there by default and only referencing them internally. If we did this, there would need to be a mechanism to subsequently unregister these results in order to delete them (since they do not wish to remain permanently, as with other pipeline results). 
\npar With regard to the second issue of handling test-generated results, we have three main choices. One is to allow for a `test mode' which would let pipelines be modified and suppress the caching of results. Pipelines in test mode could not be published, and results from test mode runs would be discarded. This has the advantage of keeping everything under test tidily away from running pipelines. However, this prevents partial results from test pipelines being shared with each other, and also means that the `successful' iteration will need to be run twice - once in testing, and another after being published. This is sub-optimal. Also, there will undoubtedly come a time where somebody relies upon results generated in test mode, which we will not have the relevant backing provenance for.
\npar The second approach is similar to that used in git and other version control systems. In this approach, every pipeline has a unique identity as a function of its components and architecture. When a test pipeline is run, this is run as a full pipeline and results generated are subject to tracking and caching as usual. However, at some point a pipeline can also be tagged with a `friendly' name. This is effectively the publication of a pipeline; only tagged pipelines appear in the catalogue, and untagged pipelines are only visible (on request) to their creators. Under the covers, however, results can still be shared between them and tagged pipelines.
\npar The final approach, and one which may work either in conjunction with either of the two preceding approaches or on its own, is to have a separate test instance in which testing takes place before publishing a complete pipeline to the live system. This means that testing can be done at a lower priority than other activities, is guaranteed not to interfere with them, and can be done from a completely fresh start each time (by purging the test system every so often). This offers the best situation in terms of isolating testing, but potentially does not allow pipeline creators to exercise every possible scenario that would be faced in the real system.
\subsubsection{Pipeline Runner}
\npar The pipeline runner will be running existing pipelines, either on their own behalf or on behalf of another user. In the latter case, the pipeline runner will probably be within HGI, but in the former case the user may be from any faculty group. Whilst running a pipeline is the defining operation for this role, they will need to perform a number of distinct actions within the system:
\begin{itemize}
\item Viewing the pipeline catalogue and selecting an appropriate pipeline.
\item Configuring the pipeline to bind free inputs to constants or data sources which they have access to.
\item Submitting a configured pipeline to an execution queue.
\item (For HGI users) Submitting a configured pipeline to an execution queue with the permissions of another group.
\item Monitor the status of an owned pipeline in the execution queue or in execution.
\item Manually pause or stop an in-progress pipeline.\footnote{Though note that this may not actually stop the execution of steps in the pipeline, since there is no guarantee that the step itself is owned by the same user as the pipeline - it may have been de-duplicated against an identical step being run by another user.}
\item See any progress indicators or debugging information generated by the pipeline.
\end{itemize}
\subsection{System Interactions}
\subsubsection{LDAP or other configuration systems}
\label{sec:interactions:ldap}
\subsubsection{Sequencescape or project-management systems}
\section{Functional Components} 
\printglossaries
\end{document}
